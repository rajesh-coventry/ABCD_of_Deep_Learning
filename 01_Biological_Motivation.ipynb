{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98aa9456",
   "metadata": {},
   "source": [
    "# **Biological Motivation of Neural Networks:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b141c7d5",
   "metadata": {},
   "source": [
    "> ![](https://upload.wikimedia.org/wikipedia/commons/thumb/1/10/Blausen_0657_MultipolarNeuron.png/1200px-Blausen_0657_MultipolarNeuron.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa84b19a",
   "metadata": {},
   "source": [
    "The entire concept of Artificial Neural Networks is inspired by the structure and function of the **`biological nervous system`**, primarily the **`human brain`**. The goal is to create a computational system that can learn and adapt in a way similar to how humans do.\n",
    "\n",
    "The fundamental building block in both systems is the `\"neuron.\"`\n",
    "\n",
    "### **The Biological Neuron:**\n",
    "\n",
    "The human brain is made up of billions of specialized cells called **`neurons`**. These cells are responsible for processing and transmitting information through electrical and chemical signals. \n",
    "\n",
    "**Here are the key components of a biological neuron and their functions:**\n",
    "\n",
    "| Component | Description | Function |\n",
    "| :--- | :--- | :--- |\n",
    "| **Dendrites** | Tree-like branches extending from the cell body. | **Receive signals** from other neurons. |\n",
    "| **Soma** (Cell Body) | The main part of the neuron. | **`Sums up`** the received signals (inputs). |\n",
    "| **`Axon`** | A long, slender projection. | **`Transmits the output signal`** to other neurons. |\n",
    "| **`Axon Terminals`** | Endpoints of the axon. | **`Pass the signal`** across the synapse to the next neuron. |\n",
    "| **`Synapse`** | The tiny gap between the axon terminal of one neuron and the dendrite of another. | **`Controls the strength and nature`** of the signal transmission (connection weight). |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29160cb2",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2479dc",
   "metadata": {},
   "source": [
    "### **Signal Transmission and Activation:**\n",
    "\n",
    "The process of information flow in the brain is what truly motivated the mathematical model:\n",
    "\n",
    "1.  **Input Accumulation:** A neuron receives electrical signals from thousands of other neurons via its dendrites. These signals are either **excitatory** (pushing the neuron to fire) or **inhibitory** (stopping it from firing).\n",
    "\n",
    "2.  **Weighted Sum:** At the soma, these inputs are \"summed up,\" but critically, the **synapses** (the connections) have different *strengths*. A stronger synapse means the input from that connection has a bigger impact on the sum. This is the biological equivalent of **connection weights** in an ANN.\n",
    "\n",
    "3.  **Threshold (Activation):** The neuron only \"fires\" (sends an output signal down the axon) if the accumulated sum of inputs is strong enough to cross a certain **threshold**.\n",
    "\n",
    "4.  **Output:** If the threshold is crossed, the neuron generates an electrical impulse (an action potential) that travels down the axon to influence thousands of other neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace99dae",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2d4d0b",
   "metadata": {},
   "source": [
    "### **Translating Biology to Artificial Neural Networks (ANNs):**\n",
    "\n",
    "The structure and mechanism of the biological neuron were directly modeled to create the **Artificial Neuron** (often called a **Perceptron**). \n",
    "\n",
    "| Biological Component | Artificial Neural Network Equivalent | Description |\n",
    "| :--- | :--- | :--- |\n",
    "| **Dendrites** | **Input connections ($x_i$)** | The data points fed into the neuron. |\n",
    "| **Synapse Strength** | **Weights ($w_i$)** | A numerical value assigned to an input, determining its importance. This is what the network *learns*. |\n",
    "| **Soma/Summation** | **Weighted Sum ($\\sum w_i x_i + b$)** | The process of multiplying each input by its weight and adding a bias term ($b$). |\n",
    "| **Threshold** | **Activation Function ($f$)** | A mathematical function that decides whether the neuron should \"fire\" (pass on a signal) based on the weighted sum. Common examples are ReLU or Sigmoid. |\n",
    "| **Axon/Output** | **Output Signal ($y$)** | The result of the activation function, which becomes the input for the next layer of neurons. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41b49ac",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805de904",
   "metadata": {},
   "source": [
    "### **The Core Biological Motivation: Learning:**\n",
    "\n",
    "The most powerful motivation is the brain's ability to **`learn and adapt`**.\n",
    "\n",
    "* **`Plasticity`:** The brain is `plastic`, meaning the connections (synapses) between neurons can change strength over time based on new experiences. If two neurons are often active at the same time, the connection between them strengthens —a concept often summarized as `\"neurons that fire together, wire together.\"`\n",
    "\n",
    "* **`ANN Learning`:** In an ANN, this biological process is mirrored by the **`training algorithm`** (like backpropagation). When the network makes a mistake, the **`weights` ($w_i$)** (the artificial synapses) are adjusted to make the output more accurate next time.\n",
    "\n",
    "In essence, an ANN **`learns`** by adjusting the **strength of its connections (weights)**, just as the biological brain learns by adjusting the **strength of its synapses**. This iterative, adaptive adjustment is the core biological principle that drives the success of neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9115285",
   "metadata": {},
   "source": [
    "----------\n",
    "-----\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628ebb9a",
   "metadata": {},
   "source": [
    "### **What is a neuron? (dendrites, soma, axon):**\n",
    "\n",
    "> ![](https://cdn1.byjus.com/wp-content/uploads/2020/02/STRUCTURE-OF-NEURON.png)\n",
    "\n",
    "Think of a neuron as a tiny electrical processing unit with three main regions:\n",
    "\n",
    "* **`Dendrites`** — the antennae.\n",
    "  Many branch-like processes that **`receive`** chemical signals from other neurons. Each incoming connection lands on a dendrite.\n",
    "\n",
    "* **`Soma` (cell body)** — the integrator / “computer.”\n",
    "  The soma collects incoming signals and integrates them into a single internal quantity called the **`membrane potential`**.\n",
    "\n",
    "* **`Axon`** — the output cable.\n",
    "  If the soma’s membrane potential crosses a threshold, the neuron sends a stereotyped electrical pulse (an **`action potential`** or **`spike`**) down the axon to other neurons. The axon can branch and contact many other neurons.\n",
    "\n",
    "Simple visual ($ASCII$):\n",
    "\n",
    "```py \n",
    "  many inputs --> [ DENDRITES ] --> ( SOMA / INTEGRATOR ) --> [ AXON ] ---> outputs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe4a552",
   "metadata": {},
   "source": [
    "> ![](https://towardsdatascience.com/wp-content/uploads/2021/12/1hkYlTODpjJgo32DoCOWN5w.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b081b045",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0c6548",
   "metadata": {},
   "source": [
    "### **What is a synapse?**\n",
    "\n",
    "> ![](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTk79WS7MH8FTGAX3ueTtiPYvenC4j_YD6IDA&s) \n",
    "\n",
    "A **`synapse`** is the connection point between the axon terminal of one neuron and the dendrite (or soma) of another. It’s not just a wire — it’s a tiny electro-chemical interface:\n",
    "\n",
    "* When a spike arrives at a presynaptic axon terminal, it causes release of **`neurotransmitter`** molecules into the synaptic gap.\n",
    "\n",
    "* Neurotransmitters bind to receptors on the postsynaptic membrane and cause **`ion channels`** to open/close, changing the postsynaptic neuron’s membrane potential.\n",
    "\n",
    "* Synapses can be **`excitatory`** (depolarize the postsynaptic membrane — makes firing more likely) or **`inhibitory`** (hyperpolarize — makes firing less likely).\n",
    "\n",
    "* The **`strength`** of a synapse (how much influence it has) is often called **`synaptic weight`** in analogy to machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca84d21",
   "metadata": {},
   "source": [
    "> ![](https://www.researchgate.net/profile/Jacek-Gosciniak/publication/353208522/figure/fig3/AS:1044994899062786@1626157607706/a-Schematic-illustration-of-biological-neurons-and-synapse-Signals-are-transferred.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacdc29b",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910da4bc",
   "metadata": {},
   "source": [
    "### **What does it mean for a neuron to `“fire”`?**\n",
    "\n",
    "* A neuron’s membrane has an electrical potential (voltage) across it. Inputs change that voltage.\n",
    "\n",
    "* Neurons integrate incoming currents; if the **`membrane potential`** at the soma reaches a certain **`threshold`**, the neuron generates an **`action potential`** — a rapid, stereotyped spike.\n",
    "\n",
    "* The spike is all-or-none: once threshold is crossed the neuron emits a spike of nearly fixed shape and amplitude.\n",
    "\n",
    "* After a spike there’s a **`refractory period`** during which the neuron is less likely (or unable) to fire again immediately.\n",
    "\n",
    "**`Important`**: firing is a discrete event (spike), but information can be represented either by spike **`rates`** (how many spikes per second) or by precise **`timing`** of spikes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30bbd1c",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74df6e9",
   "metadata": {},
   "source": [
    "### **Electrical signals → spikes (action potentials):**\n",
    "\n",
    "* Inputs at synapses change ionic flows across the membrane (Na+, K+, Cl-, Ca+), which changes membrane voltage.\n",
    "\n",
    "* Small inputs cause small voltage changes (postsynaptic potentials). These add up—**`temporally`** (over time) and **`spatially`** (across different dendrites).\n",
    "\n",
    "* If summation is sufficient and reaches threshold, voltage-gated channels open rapidly → **`action potential`**.\n",
    "\n",
    "* The action potential travels down the axon and triggers neurotransmitter release at downstream synapses.\n",
    "\n",
    "**Two common modeling simplifications:**   \n",
    "* **Integrate-and-fire model:** sum inputs into membrane potential; when it crosses threshold, emit spike and reset.\n",
    "\n",
    "* **Rate model:** ignore individual spikes; replace spike train by an average firing rate (spikes per second) and treat that as a continuous value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cc39b1",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f5687b",
   "metadata": {},
   "source": [
    "### **Neurons combine signals and produce an output:**\n",
    "\n",
    "**Putting it together:**\n",
    "\n",
    "1. Each synapse produces a postsynaptic effect proportional to (presynaptic activity × synaptic strength).\n",
    "\n",
    "2. The soma **`sums`** these effects to form an internal activation (membrane potential).\n",
    "\n",
    "3. If activation ≥ threshold → neuron emits a spike (output).\n",
    "\n",
    "4. The spike affects downstream neurons via their synapses.\n",
    "\n",
    "**This is exactly the intuition behind the perceptron:** inputs are combined, a threshold is applied, and an output is produced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a580ef00",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d48c6c",
   "metadata": {},
   "source": [
    "### **Biological → perceptron: a clean mapping:**\n",
    "\n",
    "| Biology                                   |         Intuition / Role | Perceptron (mathematical)                                |\n",
    "| ----------------------------------------- | -----------------------: | -------------------------------------------------------- |\n",
    "| Presynaptic neuron activity (spikes/rate) |             Input signal | ($x_i$) (input feature)                                    |\n",
    "| Synapse strength (efficacy)               |   Scales input influence | ($w_i$) (weight)                                           |\n",
    "| Dendritic + somatic integration           |  Summation of influences | Weighted sum ($z = \\sum_i w_i x_i + b$)                    |\n",
    "| Threshold for firing                      |        Decision boundary | Activation function (step): ($y=\\mathbf{1}[z \\ge 0]$)      |\n",
    "| Spike (all-or-none)                       |             Output event | Output 0 or 1 (or rate in rate-based models)             |\n",
    "| Synaptic plasticity (Hebbian, etc.)       | Learning / weight change | Update rule for ($w_i$) (e.g., perceptron rule, Hebb rule) |\n",
    "\n",
    "**Simple perceptron equation:**\n",
    "\n",
    "> $$z = \\sum_{i} w_i x_i + b \\qquad\n",
    "\\text{output} =\n",
    "\\begin{cases}\n",
    "1 & \\text{if } z \\ge 0\\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}$$\n",
    "\n",
    "Where ($b$) (bias) is like a constant input or resting membrane potential that shifts the effective threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e61e9c2",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d9844e",
   "metadata": {},
   "source": [
    "### **Extra biological details that matter (and what we simplify away):**\n",
    "\n",
    "Real neurons are more complex. Here’s what we usually **`ignore`** when using perceptrons, plus why it still works as a foundation:\n",
    "\n",
    "* **Temporal dynamics & spike timing.** Real neurons care about timing (millisecond precision). Perceptrons usually collapse time into static inputs or firing rates.\n",
    "\n",
    "* **Nonlinear dendritic processing.** Dendrites can perform local nonlinear computations; perceptrons treat inputs as linearly summed.\n",
    "\n",
    "* **Different neurotransmitters and modulatory systems.** Biology has context-dependent modulation (attention, neuromodulators); simple models don’t.\n",
    "\n",
    "* **Stochasticity.** Real synapses and spikes are noisy. Perceptrons are deterministic (unless you add noise).\n",
    "\n",
    "* **Homeostasis & complex plasticity.** Learning rules in biology are richer than simple Hebbian updates (they include stabilization, decay, eligibility traces, etc.).\n",
    "\n",
    "Even with those simplifications, the perceptron captures the **`core computational motif`**: *weighted combination → threshold → output*, and that’s why studying biological neurons is useful for intuition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3081084",
   "metadata": {},
   "source": [
    "### **Hebb’s Law placed in this picture:**\n",
    "\n",
    "Hebb’s rule says roughly:\n",
    "\n",
    "> If presynaptic activity and postsynaptic activity occur together, increase the synaptic strength.\n",
    "\n",
    "In math-like form (very simple):\n",
    "\n",
    "> $$\\Delta w_i \\propto x_i \\cdot y$$\n",
    "\n",
    "where ($x_i$) is presynaptic activity and (y) is postsynaptic activity. This gives the intuition that co-activation strengthens connections — the conceptual seed for learning rules used in artificial networks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404a12c5",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9a951d",
   "metadata": {},
   "source": [
    "### **Quick hands-on mental exercises:**\n",
    "\n",
    "1. Imagine two input neurons that both fire when you see a red square. A third neuron receives their signals. If both inputs arrive together often, the third neuron will start firing more reliably for red squares — that’s Hebbian strengthening.\n",
    "\n",
    "2. Draw a line separating two classes of 2D points. Think: each input dimension is a presynaptic neuron; the line is where the perceptron’s weighted sum equals threshold.\n",
    "\n",
    "3. Consider adding a strong inhibitory synapse (negative weight). That input will push the weighted sum down, preventing firing for certain patterns.\n",
    "\n",
    "\n",
    "A biological neuron collects many scaled inputs at its dendrites, sums them in the soma, and emits an all-or-none spike when the summed input crosses a threshold — exactly the idea the perceptron captures with weights, a bias, and a step activation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0980c0",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd9af09",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
