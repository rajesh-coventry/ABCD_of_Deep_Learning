{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a06c684f",
   "metadata": {},
   "source": [
    "# **Dimensions of a Single Perceptron Unit:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137819eb",
   "metadata": {},
   "source": [
    "Think of a **perceptron** as a tiny decision-maker. It takes in several pieces of information, weighs their importance, and makes a single yes/no (or +1/-1) decision.\n",
    "\n",
    "\n",
    "### **1. Input ($x$)**\n",
    "\n",
    "* The data we feed into the perceptron. For example, if we're predicting house prices, inputs could be: `[size_in_sqft, number_of_bedrooms, age_of_house]`.\n",
    "\n",
    "*   **Dimension:** $(n, 1)$ or often just said to be $n$.\n",
    "    *   $n$ is the **`number of features`** in our input.\n",
    "    \n",
    "    *   In our example, $n = 3$. So our input is a **`vector`** (a list of numbers) with 3 elements.\n",
    "    \n",
    "    *   **Example:** $x = [x₁, x₂, x₃]^T$ (a column with 3 rows).\n",
    "\n",
    "**Input is an $n$-dimensional vector.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ec9d95",
   "metadata": {},
   "source": [
    "#### **2. Weight ($w$):**\n",
    "* Each input feature has a corresponding **`weight`**. The weight determines how important that feature is for the decision. A higher absolute weight means the feature is more influential.\n",
    "\n",
    "*   **Dimension:** $(n, 1)$ or $n$ — **exactly the same as the input**.\n",
    "    * We need one weight per input feature. So if you have 3 input features, you need 3 weights.\n",
    "    \n",
    "    * **Example:** $w = [w₁, w₂, w₃]^T$ (a column with 3 rows).\n",
    "\n",
    "* During calculation, the perceptron computes the **dot product**: $w₁*x₁ + w₂*x₂ + w₃*x₃$. For this to work, $w$ and $x$ must have the same number of elements.\n",
    "\n",
    "**Weight is an $n$-dimensional vector. One weight per input.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153720fb",
   "metadata": {},
   "source": [
    "#### **Bias ($b$):**\n",
    "* An extra, tunable parameter that acts like a **`threshold`**. It allows the perceptron to shift its decision boundary away from the origin $(0,0,...)$. Think of it as the perceptron's built-in `\"preference\"` before seeing any input.\n",
    "\n",
    "* **Dimension:** $(1, )$ or **a single number (a scalar)**.\n",
    "    * There is only **`one bias`** per perceptron, regardless of how many inputs there are.\n",
    "\n",
    "* **Key Operation:** The bias is simply added to the dot product: $w·x + b$.\n",
    "\n",
    "**Bias is a single number.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bd29af",
   "metadata": {},
   "source": [
    "#### **Output ($ŷ$ or \"y-hat\"):**\n",
    "* The final decision/prediction of the perceptron. A simple perceptron uses an **activation function** (like a step function) to convert the weighted sum into a clear output.\n",
    "\n",
    "* **Dimension:** $(1, )$ or **a single number (a scalar)**.\n",
    "    *   A single perceptron always gives **`one output`**. That output could be:\n",
    "        *   Binary: `0` or `1`\n",
    "        *   Binary: `-1` or `+1`\n",
    "        *   In a more advanced `\"neurons,\"` it could be a probability or any real number.\n",
    "\n",
    "* **The Full Calculation:**\n",
    "    1.  $z = (w₁*x₁ + w₂*x₂ + w₃*x₃) + b$, `z` is a single number.\n",
    "    \n",
    "    2.  $ŷ = activation_{function}(z)$, $ŷ$ is also a single number.\n",
    "\n",
    "- **Output is a single number.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8813a5a",
   "metadata": {},
   "source": [
    "This is the foundation. When you connect many perceptrons into a **`layer`**, these dimensions expand into matrices, but the core idea remains: **`weights connect inputs to neurons, and each neuron has one bias and gives one output`.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b83963a",
   "metadata": {},
   "source": [
    "---------\n",
    "-----\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96eef1e1",
   "metadata": {},
   "source": [
    "## **Batch Processing in a Perceptron:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f2fa1f",
   "metadata": {},
   "source": [
    "Now, the Input vector Becomes a Matrix.\n",
    "\n",
    "When processing **$m$ samples** `(a batch)` with **$n$ features** each:\n",
    "\n",
    "**1. Input ($X$) - Batch Version:**\n",
    "   * Now we have **$m$ data samples**, each with **$n$ features**.\n",
    "\n",
    "   * **Dimension:** $(m, n)$ - a **matrix:**\n",
    "     * $m$: number of samples in the batch (batch size)\n",
    "     * $n$: number of features per sample\n",
    "\n",
    "* **Visual:**\n",
    "  ```py \n",
    "            Features (n)\n",
    "         ↓ ↓ ↓ ↓\n",
    "      X = [[x₁₁, x₁₂, ..., x₁ₙ],  ← Sample 1\n",
    "            [x₂₁, x₂₂, ..., x₂ₙ],  ← Sample 2\n",
    "            ...\n",
    "            [xₘ₁, xₘ₂, ..., xₘₙ]]   ← Sample m\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3f550c",
   "metadata": {},
   "source": [
    "**2. Weight ($w$) - Stays the Same!**\n",
    "\n",
    "   * **Dimension:** Still $(n, 1)$ or $n$ - a **`vector`**\n",
    "   \n",
    "   * The **`same weights`** are applied to **`all samples`** in the batch.\n",
    "   \n",
    "   * **Visual:** $w = [w₁, w₂, ..., wₙ]^T$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a8f477",
   "metadata": {},
   "source": [
    "**3. Bias ($b$) - Still a Single Number:**  \n",
    "\n",
    "   * **Dimension:** Still $(1, )$ - a **`scalar`**\n",
    "   * **Important:** This same bias is added to **`every sample's calculation`**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf27792",
   "metadata": {},
   "source": [
    "**4. Output ($Ŷ$) - Now a Vector:**\n",
    "   \n",
    "   * **Dimension:** $(m, 1)$ or $m$ - a **`vector`** with $m$ outputs\n",
    "   \n",
    "   * **One output per sample in the batch**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843797b9",
   "metadata": {},
   "source": [
    "#### **The Mathematics: Batch Calculation:**   \n",
    "\n",
    "**The Core Operation: Matrix-Vector Multiplication:**     \n",
    "   1. For a single sample: $z = w·x + b$ (dot product + bias)   \n",
    "\n",
    "   2. For a batch: $Z = X @ w + b$ (matrix multiplication + broadcasting)\n",
    "\n",
    "**Step-by-step:**\n",
    "\n",
    "1. **Matrix Multiplication:** $X @ w$\n",
    "   ```py \n",
    "   [x₁₁, x₁₂, ..., x₁ₙ]   [w₁]   [x₁₁*w₁ + x₁₂*w₂ + ... + x₁ₙ*wₙ]   [z₁]\n",
    "   [x₂₁, x₂₂, ..., x₂ₙ] × [w₂] = [x₂₁*w₁ + x₂₂*w₂ + ... + x₂ₙ*wₙ] = [z₂]\n",
    "   ...                    ...      ...                             ...\n",
    "   [xₘ₁, xₘ₂, ..., xₘₙ]   [wₙ]    [xₘ₁*w₁ + xₘ₂*w₂ + ...   + xₘₙ*wₙ]  [zₘ]\n",
    "   ```\n",
    "   Result: A vector $Z_{raw}$ of shape $(m, 1)$\n",
    "\n",
    "2. **Add Bias (Broadcasting):** $Z = Z_{raw} + b$\n",
    "   ```py \n",
    "         [z₁]   [b]   [z₁ + b]\n",
    "         [z₂] + [b] = [z₂ + b]\n",
    "         ...    ...   ...\n",
    "         [zₘ]   [b]   [zₘ + b]\n",
    "   ```\n",
    "   The scalar $b$ is automatically `\"broadcast\"` to add to every element.\n",
    "\n",
    "3. **Apply Activation Function:** $Ŷ = activation\\_function(Z)$\n",
    "   ```py \n",
    "         [activation(z₁ + b)]\n",
    "         [activation(z₂ + b)]\n",
    "         ...\n",
    "         [activation(zₘ + b)]\n",
    "   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d0b94e",
   "metadata": {},
   "source": [
    "## **Example:**\n",
    "\n",
    "Let's use our `\"go for a walk\"` perceptron with a batch of $3$ people:\n",
    "\n",
    "**Input Matrix X ($3$ people × $3$ features):**\n",
    "   - Person 1: `[Sunny=8, Time=1.5, Energy=6]`\n",
    "   - Person 2: `[Sunny=3, Time=2.0, Energy=4]`\n",
    "   - Person 3: `[Sunny=10, Time=0.5, Energy=9]`\n",
    "\n",
    "```py \n",
    "               Weather,  Time,  Energy\n",
    "         X =   [[8,      1.5,    6],    ← Person 1\n",
    "               [3,       2.0,    4],    ← Person 2  \n",
    "               [10,      0.5,    9]]    ← Person 3\n",
    "         Dimensions: (3, 3)\n",
    "```\n",
    "\n",
    "**Weights (same as before):**\n",
    "```py \n",
    "w = [2.0,    ← Weather weight\n",
    "     0.5,    ← Time weight\n",
    "     0.8]    ← Energy weight\n",
    "Dimensions: (3, 1)\n",
    "```\n",
    "\n",
    "**Bias:**\n",
    "```py \n",
    "      b = -10  ← Same threshold\n",
    "```\n",
    "\n",
    "**Calculation:**\n",
    "\n",
    "1. **Matrix Multiplication:**\n",
    "   ```py \n",
    "   Person 1: (8×2.0) + (1.5×0.5) + (6×0.8) = 16 + 0.75 + 4.8 = 21.55\n",
    "   Person 2: (3×2.0) + (2.0×0.5) + (4×0.8) = 6 + 1.0 + 3.2 = 10.2\n",
    "   Person 3: (10×2.0) + (0.5×0.5) + (9×0.8) = 20 + 0.25 + 7.2 = 27.45\n",
    "   \n",
    "   Z_raw = [21.55, 10.2, 27.45]^T\n",
    "   ```\n",
    "\n",
    "2. **Add Bias:**\n",
    "   ```py \n",
    "         Z = [21.55 - 10, 10.2 - 10, 27.45 - 10]\n",
    "         = [11.55, 0.2, 17.45]\n",
    "   ```\n",
    "\n",
    "3. **Apply Step Function (output 1 if z > 0, else 0):**\n",
    "   ```py \n",
    "         Ŷ = [1, 1, 1]^T\n",
    "   ```\n",
    "   All three people should go for a walk!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a26198",
   "metadata": {},
   "source": [
    "#### **Why Batches Are Important:**\n",
    "\n",
    "1. **`Computational Efficiency`:** Modern hardware (GPUs/TPUs) is optimized for parallel matrix operations.\n",
    "\n",
    "2. **`Stable Learning`:** When updating weights during training, using batches gives a better estimate of the true gradient than a single sample.\n",
    "\n",
    "3. **`Vectorization`:** One matrix operation processes all samples at once, much faster than looping through samples individually."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4dd53e",
   "metadata": {},
   "source": [
    "| Component | Symbol | Single Sample | Batch (m samples) |\n",
    "|-----------|--------|---------------|-------------------|\n",
    "| **Input** | `x` or `X` | `(n,)` vector | `(m, n)` matrix |\n",
    "| **Weight** | `w` | `(n,)` vector | `(n,)` vector (unchanged) |\n",
    "| **Bias** | `b` | `(1,)` scalar | `(1,)` scalar (unchanged) |\n",
    "| **Output** | `ŷ` or `Ŷ` | `(1,)` scalar | `(m,)` vector |"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
