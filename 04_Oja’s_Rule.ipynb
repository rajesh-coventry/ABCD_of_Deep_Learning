{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a7eab83",
   "metadata": {},
   "source": [
    "# **Oja's Rule:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46381be2",
   "metadata": {},
   "source": [
    "**Oja’s rule naturally follows Hebbian learning**, both **historically and conceptually**. What comes next is not a new neuron, but a **fix to a fundamental flaw** in Hebb’s rule.\n",
    "\n",
    "**Why Oja’s rule was needed (what Hebb could not do):**\n",
    "\n",
    "**Problem with Hebbian learning:**\n",
    "\n",
    "Recall classical Hebb:\n",
    "\n",
    "> $\\Delta w = \\eta x y\n",
    "\\quad\\text{where}\\quad\n",
    "y = w^\\top x$ \n",
    "\n",
    "This causes a **serious issue**:   \n",
    "   * If inputs are correlated with the output,\n",
    "   * Weights keep growing **`without bound`**\n",
    "   * There is no stabilization mechanism\n",
    "\n",
    "Biologically this is unrealistic.\n",
    "Mathematically this makes learning **`unstable`**.\n",
    "\n",
    "So the open question after Hebb was:\n",
    "\n",
    "> *How can synapses strengthen through correlation **`without exploding`**?*\n",
    "\n",
    "This is exactly what **`Oja’s rule`** answers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b65150",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345d0f44",
   "metadata": {},
   "source": [
    "## **What is Oja’s Rule? (high-level idea):**\n",
    "\n",
    "**Oja’s rule** is a **normalized Hebbian learning rule** that:   \n",
    "   * Preserves Hebb’s intuition (“fire together → strengthen”)\n",
    "   * Automatically prevents weight explosion\n",
    "   * Introduces self-stabilization\n",
    "\n",
    "It was proposed by **Erkki Oja (1982)**.\n",
    "\n",
    "In one sentence:\n",
    "\n",
    "> **Oja’s rule is Hebbian learning plus automatic weight normalization.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c827a518",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ed5a02",
   "metadata": {},
   "source": [
    "## **How Oja’s Rule Connects to Earlier Models:**\n",
    "\n",
    "| Concept    | Contribution                    |\n",
    "| ---------- | ------------------------------- |\n",
    "| MCP neuron | Computation (threshold unit)    |\n",
    "| Hebb       | Local learning via correlation  |\n",
    "| **Oja**    | Stable learning + normalization |\n",
    "| Perceptron | Error-driven learning           |\n",
    "\n",
    "**Oja’s rule is a direct refinement of Hebb**, not a replacement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19472e20",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288cf034",
   "metadata": {},
   "source": [
    "## **Mathematics of Oja’s Rule:**\n",
    "\n",
    "We derive Oja’s rule from **first principles**, not by memorization.\n",
    "\n",
    "**Start with Hebbian learning:**\n",
    "\n",
    "> $\\Delta w = \\eta x y\n",
    "\\quad\\text{with}\\quad\n",
    "y = w^\\top x$ \n",
    "\n",
    "This increases weight magnitude continuously."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa6dc3b",
   "metadata": {},
   "source": [
    "**Impose a biological constraint:**\n",
    "\n",
    "Real neurons:  \n",
    "   * Cannot have infinite synaptic strength\n",
    "   * Must maintain bounded total input influence\n",
    "\n",
    "So we impose:\n",
    "\n",
    "> $|w|^2 = \\text{constant}$ \n",
    "\n",
    "This means learning must include **`normalization`**.\n",
    "\n",
    "**Add a corrective decay term:**\n",
    "\n",
    "We want:   \n",
    "   * Hebbian growth when correlated\n",
    "   * Decay proportional to current weight strength\n",
    "\n",
    "The simplest local decay term involving only ($w$) and ($y$) is:\n",
    "\n",
    ">  $-\\eta y^2 w$ \n",
    "\n",
    "This gives:\n",
    "\n",
    "> $\\boxed{\n",
    "\\Delta w = \\eta \\left( x y - y^2 w \\right)\n",
    "}$ \n",
    "\n",
    "This is **Oja’s rule**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0753affb",
   "metadata": {},
   "source": [
    "**Why this stabilizes weights?**\n",
    "\n",
    "* When weights grow too large → ($y^2 w$) dominates → weights shrink\n",
    "* When weights are small → Hebbian term dominates → learning proceeds\n",
    "\n",
    "**At equilibrium:**\n",
    "\n",
    "> $\\Delta w = 0\n",
    "\\Rightarrow x y = y^2 w\n",
    "\\Rightarrow w \\propto \\mathbb{E}[x y]$ \n",
    "\n",
    "Weights converge to a **`stable direction`**, not infinite magnitude."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9229182b",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6ccf93",
   "metadata": {},
   "source": [
    "## **Logical / Intuitive Meaning of Oja’s Rule:**\n",
    "\n",
    "**Oja’s rule means:**\n",
    "\n",
    "> “Strengthen connections that consistently explain the output, but weaken them proportionally to how dominant they already are.”\n",
    "\n",
    "In simpler words:     \n",
    "* Learn **important correlations**\n",
    "* Forget **redundant strength**\n",
    "\n",
    "This introduces:   \n",
    "* Competition between synapses\n",
    "* Automatic balance\n",
    "* Self-organization\n",
    "\n",
    "This is closer to biological plasticity than raw Hebbian learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094b9d74",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c80d23",
   "metadata": {},
   "source": [
    "## **Geometric Meaning (Very Important):**\n",
    "\n",
    "This is where Oja’s rule becomes powerful.\n",
    "\n",
    "**Key result:** **Oja’s rule learns the first principal component of the data.**\n",
    "\n",
    "**Let:**   \n",
    "   * Input vectors: ($x$)\n",
    "   * Weight vector: ($w$)\n",
    "   * Output: ($y = w^\\top x$)\n",
    "\n",
    "Geometrically:   \n",
    "   * Learning rotates ($w$)\n",
    "   * Until it aligns with the direction of **`maximum variance`**\n",
    "\n",
    "**So**:   \n",
    "   * The neuron becomes a **`feature detector`**\n",
    "   * It extracts the dominant direction in input space\n",
    "\n",
    "This is essentially **`Principal Component Analysis` ($PCA$)** using a single neuron."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0a64a9",
   "metadata": {},
   "source": [
    "## **Geometric Picture:**\n",
    "\n",
    "* Inputs form a cloud in space\n",
    "* Oja’s rule rotates the weight vector\n",
    "* The weight vector converges to the main axis of the cloud\n",
    "\n",
    "This is **unsupervised representation learning**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191c5e97",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4afbda",
   "metadata": {},
   "source": [
    "## **What Success we have Achieved at this Stage:**\n",
    "\n",
    "By the time we reach Oja’s rule, we have achieved:\n",
    "\n",
    "✅ A mathematically defined neuron ($MCP$)                \n",
    "✅ Local learning ($Hebb$)    \n",
    "✅ Stable learning ($Oja$)  \n",
    "✅ Unsupervised feature extraction      \n",
    "✅ Geometric interpretation of learning       \n",
    "✅ Biological plausibility (local, no labels)   \n",
    "\n",
    "This is a **`huge conceptual success`**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b152e1ee",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68173f9",
   "metadata": {},
   "source": [
    "## **What Still Remains to Reach the Modern Perceptron:**\n",
    "\n",
    "Despite this progress, **`critical gaps remain`**:\n",
    "\n",
    "**1. No task objective:**   \n",
    "* Oja learns variance, not correctness\n",
    "* No notion of “right vs wrong”\n",
    "\n",
    "**2. No supervised learning:**    \n",
    "* Cannot learn labels\n",
    "* Cannot solve classification tasks reliably\n",
    "\n",
    "**3. No decision boundary optimization:**  \n",
    "* Finds directions, not separators\n",
    "\n",
    "**4. No bias handling:**  \n",
    "* Cannot shift thresholds flexibly\n",
    "\n",
    "**5. No multi-neuron coordination:**   \n",
    "* No error sharing across layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40fcaee",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16413fa",
   "metadata": {},
   "source": [
    "## **What Concept Comes Next?**\n",
    "\n",
    "To reach the **modern perceptron**, we need:\n",
    "\n",
    "> **Error-driven learning**\n",
    "\n",
    "**That means:**    \n",
    "   * Compare output to target\n",
    "   * Adjust weights based on *mistake*\n",
    "   * Introduce an explicit loss\n",
    "\n",
    "**This leads directly to:**   \n",
    "   * **Delta rule**\n",
    "   * **Perceptron learning algorithm**\n",
    "   * Eventually **gradient descent**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1c605b",
   "metadata": {},
   "source": [
    "> **Oja’s rule refines Hebbian learning by adding normalization, enabling stable, unsupervised feature learning with a clear geometric interpretation, but it still lacks error-based learning required for classification in modern perceptrons.**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
