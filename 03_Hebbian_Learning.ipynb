{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fdb89f2",
   "metadata": {},
   "source": [
    "# **Hebbian Learning:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3ebe0d",
   "metadata": {},
   "source": [
    "Hebb’s learning idea was inspired by the $MCP$ neuron.\n",
    "\n",
    "**What MCP gave first (1943)?**\n",
    "\n",
    "McCulloch–Pitts gave us:   \n",
    "   * A **fixed mathematical neuron**\n",
    "   * Binary inputs and outputs\n",
    "   * Weighted summation + threshold\n",
    "   * **No learning**\n",
    "\n",
    "Formally:\n",
    "\n",
    "> $y = H\\left(\\sum_i w_i x_i - \\theta\\right)$ \n",
    "\n",
    "This answered:\n",
    "\n",
    "> *How can neurons compute?*\n",
    "\n",
    "But it did **`not`** answer:\n",
    "\n",
    "> *How do neurons change with experience?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9060d56a",
   "metadata": {},
   "source": [
    "### **Hebb’s Missing Question (1949):**\n",
    "\n",
    "Hebb looked at $MCP$-like neurons and asked:\n",
    "\n",
    "> “If neurons are computing using connections, how do those connections get set in the first place?”\n",
    "\n",
    "So Hebb did **`not`** invent a new neuron model.\n",
    "He proposed a **rule for changing the weights of MCP-style connections over time**.\n",
    "\n",
    "**Key insight:** Hebbian learning is a **plasticity rule added on top of MCP neurons**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9528dac1",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae511ee3",
   "metadata": {},
   "source": [
    "## **Hebb’s original idea (conceptual, not mathematical):**\n",
    "\n",
    "**Hebb proposed:**\n",
    "\n",
    "> If neuron $A$ repeatedly helps neuron $B$ fire, then the synapse from $A$ to $B$ should be strengthened.\n",
    "\n",
    "**Important details:**   \n",
    "   * No teacher\n",
    "   * No error signal\n",
    "   * Learning is **local**\n",
    "   * Learning depends only on activity\n",
    "\n",
    "**This fits perfectly with the MCP neuron, because:**   \n",
    "   * $MCP$ already has inputs ($x_i$)\n",
    "   * $MCP$ already has an output ($y$)\n",
    "   * We only need a rule to update ($w_i$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80584c7",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbcd856",
   "metadata": {},
   "source": [
    "## **Mathematical derivation of Hebbian learning:**\n",
    "\n",
    "**Identify what can influence a synapse:**\n",
    "\n",
    "A synapse connects:\n",
    "\n",
    "* Presynaptic neuron activity → ($x_i$)\n",
    "* Postsynaptic neuron activity → ($y$)\n",
    "\n",
    "So any local learning rule **must** be a function of:\n",
    "\n",
    "> $x_i \\quad \\text{and} \\quad y$ \n",
    "\n",
    "No other information is locally available.\n",
    "\n",
    "**Learning should strengthen correlated activity:**\n",
    "\n",
    "**Hebb’s hypothesis:**\n",
    "\n",
    "* If ($x_i = 1$) and ($y = 1$), increase the weight\n",
    "* If either is inactive, no strengthening\n",
    "\n",
    "The simplest mathematical object that is:\n",
    "\n",
    "* Zero if either input is zero\n",
    "* Positive if both are positive\n",
    "\n",
    "is the **product**:\n",
    "\n",
    "> $x_i \\cdot y$ \n",
    "\n",
    "**Introduce proportional weight change:**\n",
    "\n",
    "Weights should change gradually, not jump arbitrarily.\n",
    "\n",
    "So:\n",
    "\n",
    "> $\\Delta w_i \\propto x_i y$ \n",
    "\n",
    "Introduce a learning rate ( $\\eta > 0$ ):\n",
    "\n",
    "> $\\boxed{\\Delta w_i = \\eta , x_i y}$ \n",
    "\n",
    "This is the **classical Hebbian learning rule**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e48333",
   "metadata": {},
   "source": [
    "**Full learning dynamics:**\n",
    "\n",
    "Over time:\n",
    "\n",
    "> $w_i(t+1) = w_i(t) + \\eta x_i y$ \n",
    "\n",
    "That’s it.\n",
    "No labels.\n",
    "No errors.\n",
    "No gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a114974",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f42d9f",
   "metadata": {},
   "source": [
    "## **Why this rule fits $MCP$ neurons perfectly?**\n",
    "\n",
    "Recall MCP neuron:\n",
    "\n",
    "> $y = H\\left(\\sum_i w_i x_i - \\theta\\right)$ \n",
    "\n",
    "Hebbian learning:   \n",
    "* Uses the same ($x_i$)\n",
    "* Uses the same ($y$)\n",
    "* Only modifies ($w_i$)\n",
    "\n",
    "So Hebb **`completes`** the MCP neuron by giving it memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20728e83",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b9744b",
   "metadata": {},
   "source": [
    "## **Behavior of Hebbian learning on logical functions:**\n",
    "\n",
    "Now let’s see **what Hebbian learning actually does** for OR, NOT, and XOR.\n",
    "\n",
    "We assume:\n",
    "\n",
    "* Binary inputs ($x_i \\in {0,1}$)\n",
    "* Output ($y \\in {0,1}$)\n",
    "* MCP neuron with threshold\n",
    "\n",
    "\n",
    "**A. OR function (works well):**\n",
    "\n",
    "OR truth table: \n",
    "\n",
    "| x₁ | x₂ | y |\n",
    "| -- | -- | - |\n",
    "| 0  | 0  | 0 |\n",
    "| 1  | 0  | 1 |\n",
    "| 0  | 1  | 1 |\n",
    "| 1  | 1  | 1 |\n",
    "\n",
    "**Hebbian updates:**\n",
    "\n",
    "When output is 1:\n",
    "\n",
    "* Active input weights increase\n",
    "\n",
    "Over repeated exposure:\n",
    "\n",
    "* (w_1) increases when (x_1=1)\n",
    "* (w_2) increases when (x_2=1)\n",
    "\n",
    "Result:\n",
    "\n",
    "> $w_1 > 0,\\quad w_2 > 0$ \n",
    "\n",
    "With a low threshold, neuron fires if **`either input is active`**.\n",
    "\n",
    "✅ **Hebbian learning naturally learns OR**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db0604b",
   "metadata": {},
   "source": [
    "**2. NOT function (partially works):**\n",
    "\n",
    "NOT truth table (single input):\n",
    "\n",
    "| x | y |\n",
    "| - | - |\n",
    "| 0 | 1 |\n",
    "| 1 | 0 |\n",
    "\n",
    "Problem:\n",
    "\n",
    "When (x=0), Hebbian update is zero:\n",
    "  \n",
    "> $\\Delta w = \\eta x y = 0$ \n",
    "\n",
    "So Hebb cannot strengthen inhibitory behavior directly.\n",
    "\n",
    "Solution (historical):\n",
    "\n",
    "* Add a **bias neuron** that is always active\n",
    "* Learn negative weights manually or via constraints\n",
    "\n",
    "⚠️ **Hebbian learning alone does not naturally learn NOT**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deca5194",
   "metadata": {},
   "source": [
    "**3. XOR function (fails fundamentally):**\n",
    "\n",
    "XOR truth table:\n",
    "\n",
    "| x₁ | x₂ | y |\n",
    "| -- | -- | - |\n",
    "| 0  | 0  | 0 |\n",
    "| 1  | 0  | 1 |\n",
    "| 0  | 1  | 1 |\n",
    "| 1  | 1  | 0 |\n",
    "\n",
    "Hebbian weight updates:\n",
    "\n",
    "* When (x_1=1, x_2=0, y=1): increase (w_1)\n",
    "* When (x_1=0, x_2=1, y=1): increase (w_2)\n",
    "* When (x_1=1, x_2=1, y=0): **no update**\n",
    "\n",
    "Final result:\n",
    "\n",
    "> $w_1 > 0,\\quad w_2 > 0$ \n",
    "\n",
    "This implements **OR**, not XOR.\n",
    "\n",
    "❌ **Hebbian learning cannot learn XOR with a single MCP neuron**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e04eed5",
   "metadata": {},
   "source": [
    "## **Why XOR failure is fundamental (not a flaw of Hebb alone):**\n",
    "\n",
    "This failure happens because:\n",
    "\n",
    "* MCP neurons are **linear threshold units**\n",
    "* XOR is **not linearly separable**\n",
    "* Hebb does not change the neuron’s representational power\n",
    "\n",
    "Even perfect learning rules cannot fix a representational limitation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c3e1de",
   "metadata": {},
   "source": [
    "## **What Hebb’s rule really achieved historically?**\n",
    "\n",
    "**Hebbian learning was:**\n",
    "\n",
    "* The **first synaptic learning principle**\n",
    "* Biologically motivated\n",
    "* Local and unsupervised\n",
    "* A bridge between brain and machine\n",
    "\n",
    "But it was **not sufficient for intelligence**.\n",
    "\n",
    "**That realization directly led to:**  \n",
    "  * The Perceptron learning rule\n",
    "   * Error-driven learning\n",
    "   * Multi-layer networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca01ed5",
   "metadata": {},
   "source": [
    "\n",
    "> **Hebbian learning extends the McCulloch–Pitts neuron by introducing a local, activity-based rule for modifying synaptic weights, enabling simple associative learning but failing for non-linearly separable problems like XOR.**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
