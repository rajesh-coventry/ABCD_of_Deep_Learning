{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bae83a9a",
   "metadata": {},
   "source": [
    "# **Elements of an Artificial Neuron:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de526ce",
   "metadata": {},
   "source": [
    "> ![](https://towardsdatascience.com/wp-content/uploads/2021/11/1YA-0MyBLsn8BiThBGjycIA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b4f693",
   "metadata": {},
   "source": [
    "An artificial neuron is not a single formula — it is a **system of interacting components**, each corresponding to a biological idea and a mathematical role.\n",
    "\n",
    "Understanding these components separately helps us:  \n",
    "* See how learning happens\n",
    "* Understand where limitations come from\n",
    "* Understand how later models extend them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e3b897",
   "metadata": {},
   "source": [
    "#### **1. Inputs $(x_1, x_2, \\dots, x_n)$:**\n",
    "\n",
    "> ![](https://towardsdatascience.com/wp-content/uploads/2021/11/1IKR5o1HxTgGMIYUS0uJL7Q.png)\n",
    "\n",
    "- Inputs are numerical signals fed into the neuron.\n",
    "\n",
    "* Each input represents a **feature** of the data\n",
    "\n",
    "* Can be binary, continuous, or normalized values\n",
    "\n",
    "- Mathematically:   \n",
    "   > $x = (x_1, x_2, \\dots, x_n)$ \n",
    "\n",
    "- **Biological analogy:**   \n",
    "   * Inputs correspond to **presynaptic neuron activity**\n",
    "   * `In biology`: **spikes or firing rates**\n",
    "   * `In artificial neurons`: **numbers**\n",
    "\n",
    "- **`Intuitive Meaning`:** Inputs describe **what the neuron is seeing**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de290ec6",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be271a6",
   "metadata": {},
   "source": [
    "#### **2. Weights $(w_1, w_2, \\dots, w_n)$:**\n",
    "\n",
    "> ![](https://media.geeksforgeeks.org/wp-content/uploads/20250822111100486293/activation_function.webp) \n",
    "\n",
    "- Weights scale the influence of each input.   \n",
    "   > $w = (w_1, w_2, \\dots, w_n)$ \n",
    "\n",
    "- **Biological analogy:**   \n",
    "   * Weights correspond to **synaptic strengths**\n",
    "   * Stronger synapse → larger influence\n",
    "\n",
    "- **Intuitive meaning:** Weights encode **what the neuron cares about**.\n",
    "\n",
    "- > * Large positive weight → strong support\n",
    "- > * Large negative weight → strong inhibition\n",
    "- > * Near-zero weight → irrelevant input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5e51e9",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f1567d",
   "metadata": {},
   "source": [
    "#### **3. Weighted sum (linear combination):**\n",
    "\n",
    "> ![](https://miro.medium.com/v2/resize:fit:1400/1*upfpVueoUuKPkyX3PR3KBg.png)\n",
    "\n",
    "- It is a mathematical operation:   \n",
    "   > $z = \\sum_{i=1}^{n} w_i x_i$ \n",
    "\n",
    "- Or in vector form:   \n",
    "   > $z = w^\\top x$ \n",
    "\n",
    "- **Biological analogy:**   \n",
    "   * Dendritic and somatic integration\n",
    "   * Combining excitatory and inhibitory inputs\n",
    "\n",
    "- **Geometric meaning:**  \n",
    "   * This is a **projection** of input vector onto weight vector\n",
    "   * Measures alignment between input and learned direction\n",
    "\n",
    "**`Intuitive meaning`:** The neuron computes **how well the input matches a learned pattern**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ff3096",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549c4bc5",
   "metadata": {},
   "source": [
    "#### **4. Bias ($(b)$):**\n",
    "\n",
    "> ![](https://machine-learning.paperspace.com/~gitbook/image?url=https%3A%2F%2F2327526407-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-legacy-files%2Fo%2Fassets%252F-LvBP1svpACTB1R1x_U4%252F-LvI8vNq_N7u3RWVAPLk%252F-LvJSdcFXzoI-WW0L3w5%252Fimage.png%3Falt%3Dmedia%26token%3D84526dc6-4634-4de5-aacf-00a179afac76&width=768&dpr=4&quality=100&sign=4f478f7e&sv=2) \n",
    "\n",
    "- A constant added to the weighted sum:  \n",
    "   > $z = w^\\top x + b$ \n",
    "\n",
    "- Without bias:  \n",
    "   * The decision boundary must pass through the origin\n",
    "   * The neuron is less flexible\n",
    "\n",
    "- **Biological analogy:**   \n",
    "   * Resting membrane potential\n",
    "   * Baseline excitability\n",
    "\n",
    "- **Geometric meaning:**   \n",
    "   * Bias **shifts the hyperplane**\n",
    "   * Controls where the decision boundary lies\n",
    "\n",
    "- **Bias answers:**   \n",
    "   > “How easily should this neuron activate, even with weak input?”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823f90f7",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71da1fb8",
   "metadata": {},
   "source": [
    "#### **4. Activation Function $\\phi(\\cdot)$:**\n",
    "\n",
    "> ![](https://editor.analyticsvidhya.com/uploads/31537activationfunction.png) \n",
    "\n",
    "- A function applied to the summed input:  \n",
    "   > $y = \\phi(z)$ \n",
    "\n",
    "- **Why it matters:**   \n",
    "   * Introduces **nonlinearity**\n",
    "   * Determines output type (binary, probability, real-valued)\n",
    "\n",
    "**Common activation functions:**\n",
    "\n",
    "| Function | Purpose                          |\n",
    "| -------- | -------------------------------- |\n",
    "| Step     | Classification ($MCP$, $perceptron$) |\n",
    "| Sigmoid  | Probabilistic output             |\n",
    "| Tanh     | Zero-centered                    |\n",
    "| ReLU     | Efficient deep learning          |\n",
    "\n",
    "- **Biological analogy:**  \n",
    "   * Threshold firing\n",
    "   * Saturation effects\n",
    "\n",
    "- The activation function decides:   \n",
    "   > “Given this level of evidence, how strongly should I respond?”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a709be3c",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a203d9df",
   "metadata": {},
   "source": [
    "#### **6. Output ($y$):**\n",
    "\n",
    "> ![](https://miro.medium.com/1*WwHTEfBxoKBtCwBB9D0ByQ.png) \n",
    "\n",
    "- The final signal produced by the neuron.   \n",
    "   > $y = \\phi(w^\\top x + b)$ \n",
    "\n",
    "- **Interpretation:**   \n",
    "   * Binary decision\n",
    "   * Continuous value\n",
    "   * Probability estimate\n",
    "\n",
    "- **Biological analogy:** Spike or firing rate\n",
    "\n",
    "**`Intuitive meaning`:** The output is the neuron’s **decision or signal**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccfb2cd",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c0d10d",
   "metadata": {},
   "source": [
    "#### **7. Loss function (learning objective):**\n",
    "\n",
    "> ![](https://miro.medium.com/v2/resize:fit:1400/0*_JpWknJ6CDFcVDZP.png) \n",
    "\n",
    "- Not part of the neuron itself, but essential for learning.\n",
    "\n",
    "- Measures how wrong the output is compared to target.\n",
    "\n",
    "- **Examples:**   \n",
    "   * Squared error\n",
    "   * Cross-entropy\n",
    "\n",
    "- **The loss defines:**  \n",
    "   > “What does it mean to be wrong?”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20562aa2",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a74da6",
   "metadata": {},
   "source": [
    "#### **8. Learning Rule (weight update mechanism):**\n",
    "\n",
    "> ![](https://media.geeksforgeeks.org/wp-content/uploads/20220425162455/Artboard1.jpg) \n",
    "\n",
    "- A rule that updates weights based on data.\n",
    "\n",
    "- Examples:   \n",
    "   * Hebb rule\n",
    "   * Oja rule\n",
    "   * Delta rule\n",
    "   * Perceptron update\n",
    "\n",
    "- **Mathematical form:**   \n",
    "   > $w \\leftarrow w + \\Delta w$ \n",
    "\n",
    "- The learning rule defines:   \n",
    "   > “How should experience change the neuron?”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1d0aa5",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1a615d",
   "metadata": {},
   "source": [
    "### **Geometric summary of all components:**\n",
    "\n",
    "| Component    | Geometric role              |\n",
    "| ------------ | --------------------------- |\n",
    "| Inputs       | Points in space             |\n",
    "| Weights      | Normal vector to hyperplane |\n",
    "| Weighted sum | Projection                  |\n",
    "| Bias         | Hyperplane offset           |\n",
    "| Activation   | Partition of space          |\n",
    "| Output       | Region label                |\n",
    "\n",
    "Together, they define a **`decision surface`**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a7f17f",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238e45cc",
   "metadata": {},
   "source": [
    "### **Biological vs Artificial Summary:**\n",
    "\n",
    "| Biology    | Artificial neuron |\n",
    "| ---------- | ----------------- |\n",
    "| Dendrites  | Inputs            |\n",
    "| Synapses   | Weights           |\n",
    "| Soma       | Summation         |\n",
    "| Threshold  | Bias + activation |\n",
    "| Spike      | Output            |\n",
    "| Plasticity | Learning rule     |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fef862c",
   "metadata": {},
   "source": [
    "> *An artificial neuron consists of inputs, weights, a bias, a weighted summation, an activation function, and an output, together forming a learnable decision unit that models how biological neurons integrate signals and make decisions.*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
